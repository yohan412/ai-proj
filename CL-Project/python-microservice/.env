# LLM
LLM_PROVIDER=hf_local
HF_MODEL_ID=openai/gpt-oss-20b

# Linux + CUDA에서만 4bit 시도
HF_LOAD_IN_4BIT=true

# GPU/CPU 메모리 프로파일
HF_MAX_NEW_TOKENS=512
HF_MAX_GPU_MEMORY=18GiB
HF_MAX_CPU_MEMORY=16GiB

# 일반 설정
HF_TEMPERATURE=0.2
HF_OFFLOAD_DIR=/offload
HF_LOW_CPU_MEM=true
HF_TORCH_DTYPE=auto

# Whisper
WHISPER_MODEL=small
WHISPER_FP16=true

# Hugging Face 토큰 (여기에만! 저장소 커밋 금지)
HF_TOKEN=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

# 파편화 완화
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:64

# 공용
TZ=Asia/Seoul
HF_HOME=/models/hf
PIP_CACHE_DIR=/pipcache

TRANSFORMERS_NO_MXFP4=1
HF_USE_QUANTO=0
