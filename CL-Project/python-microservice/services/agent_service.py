# services/agent_service.py
from typing import List, Dict, Any
from services.rag_service import VideoRAG
from services.wikipedia_tool import search_wikipedia
import os
import glob

# JAVA_HOME ìë™ ì„¤ì • (KoNLPyìš©)
if 'JAVA_HOME' not in os.environ:
    print("[KoNLPy] JAVA_HOME ë¯¸ì„¤ì •, ìë™ íƒìƒ‰ ì‹œì‘...", flush=True)
    
    # 1ìˆœìœ„: java ëª…ë ¹ì–´ë¡œ ê²½ë¡œ ì°¾ê¸°
    jvm_found = False
    try:
        import subprocess
        result = subprocess.run(
            ['java', '-XshowSettings:properties', '-version'],
            capture_output=True, text=True, encoding='utf-8', errors='ignore'
        )
        for line in result.stderr.split('\n'):
            if 'java.home' in line:
                java_home = line.split('=')[1].strip()
                if os.path.exists(java_home):
                    os.environ['JAVA_HOME'] = java_home
                    print(f"[KoNLPy] JAVA_HOME ìë™ ì„¤ì •: {java_home}", flush=True)
                    jvm_found = True
                    break
    except Exception as e:
        print(f"[KoNLPy] java ëª…ë ¹ì–´ ì‹¤íŒ¨: {e}", flush=True)
    
    # 2ìˆœìœ„: ì§ì ‘ íƒìƒ‰
    if not jvm_found:
        possible_paths = [
            "C:/Program Files/Java/jdk*",
            "C:/Program Files/Java/jre*",
            "C:/Program Files (x86)/Java/jdk*",
            "C:/Program Files (x86)/Java/jre*",
        ]
        
        for pattern in possible_paths:
            matches = glob.glob(pattern)
            for match in matches:
                jvm_path = os.path.join(match, "bin", "server", "jvm.dll")
                if os.path.exists(jvm_path):
                    os.environ['JAVA_HOME'] = match
                    print(f"[KoNLPy] JAVA_HOME ìë™ ì„¤ì •: {match}", flush=True)
                    jvm_found = True
                    break
            if jvm_found:
                break
    
    if not jvm_found:
        print("[KoNLPy] âš ï¸ Javaë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. KoNLPyëŠ” íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ í´ë°±ë©ë‹ˆë‹¤.", flush=True)

def extract_keywords_pattern(question: str, lang: str) -> List[str]:
    """íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (KoNLPy í´ë°±ìš©)"""
    import re
    
    if lang == "ko":
        # ì¡°ì‚¬ ì œê±°
        cleaned = re.sub(r'(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì™€|ê³¼|ì˜|ì—ì„œ|ì—ê²Œ|ë¡œ|ìœ¼ë¡œ|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€)(?=\s|$)', '', question)
        # ì–´ë¯¸ ì œê±°
        cleaned = re.sub(r'(ë­ì•¼|ë­”ê°€|ë¬´ì—‡|ì–´ë–»ê²Œ|ì™œ|ì–¸ì œ|ì–´ë””|ëˆ„êµ¬|í•´ì¤˜|í•´ì£¼ì„¸ìš”|í•˜ì„¸ìš”)\??', '', cleaned)
        cleaned = cleaned.replace('?', '').strip()
        
        # ê³µë°±/ì‰¼í‘œ ë¶„ë¦¬
        words = cleaned.replace(',', ' ').split()
        
        # 1-5ì í•œê¸€ë§Œ
        candidates = [w for w in words if re.match(r'^[ê°€-í£]{1,5}$', w)]
        
        # ë©”íƒ€ ëª…ì‚¬ í•„í„°
        meta_nouns = {
            'ì„¤ëª…', 'ëŒ€í•´', 'ì§ˆë¬¸', 'ë‹µë³€', 'ë‚´ìš©', 'ì •ë³´', 'ì´ì•¼ê¸°', 'ì–˜ê¸°',
            'ê²ƒ', 'ê±°', 'ë­', 'ë¬´ì—‡', 'ë°©ë²•', 'ì´ìœ ', 'ì‹œê°„', 'ì¥ì†Œ', 'ì‚¬ëŒ'
        }
        
        # ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ë¯¸ ì œê±° + ë©”íƒ€ ëª…ì‚¬ ì œê±°
        verb_endings = r'(ëŒ€í•´|ì—ì„œ|ìœ¼ë¡œ|ë˜ì–´|ì´ë‹¤|ìˆë‹¤|ì—†ë‹¤|í•´ì„œ|í•˜ì—¬)$'
        keywords = [w for w in candidates 
                    if not re.search(verb_endings, w) 
                    and w not in meta_nouns]
        
        return keywords
    else:
        # ì˜ì–´
        keywords = re.findall(r'\b[A-Z][a-z]+\b|\b[a-z]{3,}\b', question)
        stopwords = {'what', 'how', 'is', 'are', 'the', 'a', 'an', 'when', 'where', 'why', 'who'}
        return [k for k in keywords if k.lower() not in stopwords]

def create_simple_qa(
    pipe,
    stored_name: str,
    segments: List[Dict],
    question: str,
    lang: str = "ko"
) -> Dict:
    """
    Simple QA Agent - Wikipedia ë‹µë³€ + ì˜ìƒ ìë§‰ ì¶œì²˜
    
    Args:
        pipe: LLM íŒŒì´í”„ë¼ì¸ (ì‚¬ìš© ì•ˆ í•¨)
        stored_name: ì˜ìƒ íŒŒì¼ëª…
        segments: ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        question: ì‚¬ìš©ì ì§ˆë¬¸
        lang: ì–¸ì–´ ì½”ë“œ
        
    Returns:
        {"answer": "ë‹µë³€", "sources": [...], "thinking_steps": []}
    """
    print(f"\n[Simple QA] ì§ˆë¬¸: {question}", flush=True)
    print(f"[Simple QA] ì˜ìƒ: {stored_name}, ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ", flush=True)
    
    try:
        # 1. ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ì œ
        import re
        
        # KoNLPy ì‹œë„ (í•œê¸€ ì „ìš©)
        keywords = []
        if lang == "ko":
            try:
                from konlpy.tag import Okt
                okt = Okt()
                
                # ëª…ì‚¬ë§Œ ì¶”ì¶œ
                nouns = okt.nouns(question)
                print(f"[Simple QA] KoNLPy ì›ë³¸ ëª…ì‚¬: {nouns}", flush=True)
                
                # ë©”íƒ€ ëª…ì‚¬ í•„í„°ë§ (ì§ˆë¬¸/ìš”ì²­ ê´€ë ¨ ë‹¨ì–´ ì œê±°)
                meta_nouns = {
                    'ì„¤ëª…', 'ëŒ€í•´', 'ì§ˆë¬¸', 'ë‹µë³€', 'ë‚´ìš©', 'ì •ë³´', 'ì´ì•¼ê¸°', 'ì–˜ê¸°',
                    'ê²ƒ', 'ê±°', 'ë­', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„êµ¬',
                    'ë°©ë²•', 'ì´ìœ ', 'ì‹œê°„', 'ì¥ì†Œ', 'ì‚¬ëŒ', 'ì•Œë ¤', 'í•´ì¤˜', 'ì£¼ì„¸ìš”'
                }
                
                # 1-5ì + ë©”íƒ€ ëª…ì‚¬ ì œì™¸
                keywords = [n for n in nouns 
                            if 1 <= len(n) <= 5 and n not in meta_nouns]
                
                print(f"[Simple QA] ë©”íƒ€ ëª…ì‚¬ ì œê±° í›„: {keywords}", flush=True)
                
            except Exception as e:
                print(f"[Simple QA] KoNLPy ì‹¤íŒ¨ ({e}), íŒ¨í„´ ë§¤ì¹­ ì‚¬ìš©", flush=True)
                # í´ë°±: íŒ¨í„´ ë§¤ì¹­
                keywords = extract_keywords_pattern(question, lang)
        else:
            # ì˜ì–´: íŒ¨í„´ ë§¤ì¹­
            keywords = extract_keywords_pattern(question, lang)
        
        # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 3ê°œ
        keywords = list(dict.fromkeys(keywords))[:3]
        print(f"[Simple QA] ìµœì¢… í‚¤ì›Œë“œ: {keywords}", flush=True)
        
        # 2. í‚¤ì›Œë“œë¡œ RAG ê²€ìƒ‰ (ì˜ìƒ ìë§‰ì—ì„œ ì¶œì²˜ ì°¾ê¸°)
        final_sources = []
        if keywords and len(segments) > 0:
            print(f"[Simple QA] RAG ê²€ìƒ‰ ì‹œì‘...", flush=True)
            rag = VideoRAG(stored_name, segments)
            all_sources = []
            
            for kw in keywords:
                results = rag.search(kw, top_k=1)  # í‚¤ì›Œë“œë‹¹ 1ê°œì”©
                all_sources.extend(results)
            
            # ì¤‘ë³µ ì œê±° (start ê¸°ì¤€)
            seen = set()
            unique_sources = []
            for src in all_sources:
                if src['start'] not in seen:
                    seen.add(src['start'])
                    unique_sources.append(src)
            
            # ì ìˆ˜ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ
            unique_sources.sort(key=lambda x: x['score'])
            final_sources = unique_sources[:3]
            
            print(f"[Simple QA] ìë§‰ ì¶œì²˜: {len(final_sources)}ê°œ", flush=True)
            for i, src in enumerate(final_sources):
                print(f"  {i+1}. [{src['start']:.1f}s] {src['text'][:50]}...", flush=True)
        else:
            print(f"[Simple QA] í‚¤ì›Œë“œ ì—†ìŒ ë˜ëŠ” ìë§‰ ì—†ìŒ, ì¶œì²˜ ìŠ¤í‚µ", flush=True)
        
        # 3. Wikipediaì—ì„œ ë‹µë³€ ìƒì„± (ê° í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰)
        print(f"[Simple QA] Wikipedia ê²€ìƒ‰ ì‹œì‘...", flush=True)
        
        wiki_results = []
        if keywords:
            for kw in keywords:
                print(f"[Simple QA]   - '{kw}' ê²€ìƒ‰ ì¤‘...", flush=True)
                wiki_result = search_wikipedia(kw, lang=lang, sentences=2)
                # [Wikipedia] ì ‘ë‘ì‚¬ ì œê±°
                cleaned = wiki_result.replace("[Wikipedia] ", "")
                # "ê²€ìƒ‰ ì‹¤íŒ¨" ë©”ì‹œì§€ê°€ ì•„ë‹ˆë©´ ì¶”ê°€
                if "ê²€ìƒ‰ ì‹¤íŒ¨" not in cleaned:
                    separator = "â”" * 30
                    wiki_results.append(f"{separator}\nğŸ“Œ {kw}\n{separator}\n{cleaned}")
        
        # í‚¤ì›Œë“œê°€ ì—†ê±°ë‚˜ ëª¨ë“  ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì§ˆë¬¸ ì „ì²´ë¡œ ê²€ìƒ‰
        if not wiki_results:
            print(f"[Simple QA]   - ì§ˆë¬¸ ì „ì²´ë¡œ ê²€ìƒ‰...", flush=True)
            wiki_answer = search_wikipedia(cleaned_question or question, lang=lang, sentences=3)
            answer = wiki_answer.replace("[Wikipedia] ", "")
        else:
            # ê° í‚¤ì›Œë“œ ê²°ê³¼ ê²°í•©
            answer = "\n\n".join(wiki_results)
        
        print(f"[Simple QA] Wikipedia ë‹µë³€: {answer[:100]}...", flush=True)
        
        return {
            "answer": answer,
            "sources": final_sources,
            "thinking_steps": []
        }
    
    except Exception as e:
        print(f"[Simple QA] ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)
        import traceback
        traceback.print_exc()
        
        return {
            "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "sources": [],
            "thinking_steps": [],
            "error": str(e)
        }

