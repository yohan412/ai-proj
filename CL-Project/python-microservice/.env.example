# LLM
LLM_PROVIDER=hf_local
HF_MODEL_ID=openai/gpt-oss-20b

# Linux + CUDA에서만 4bit 시도
HF_LOAD_IN_4BIT=true

# 12GB VRAM 프로파일(안전값)
HF_MAX_NEW_TOKENS=512
HF_MAX_GPU_MEMORY=10GiB
HF_MAX_CPU_MEMORY=20GiB

# 일반 설정
HF_TEMPERATURE=0.2
HF_OFFLOAD_DIR=/offload
HF_LOW_CPU_MEM=true
HF_TORCH_DTYPE=auto

# Whisper
WHISPER_MODEL=small
WHISPER_FP16=true

# Hugging Face 토큰(프라이빗/레이트리밋 회피 시)
HF_TOKEN=

# 파편화 완화
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:64
